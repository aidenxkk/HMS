# HMS - Hierarchical Model Structures
# Abstract
Scaling laws in machine learning indicate that larger models generally perform better when provided with more data and computation. However, this trend often fails under privacy-preserving or robustness constraints, such as Differentially Private Stochastic Gradient Descent (DP-SGD) and adversarial training, where added noise or perturbations degrade accuracy. This project investigates whether hierarchical stepwise models—composed of multiple smaller sub-classifiers—can outperform conventional monolithic models under such constrained conditions. Using CIFAR-10 and CIFAR-100 datasets, the research compares four experimental configurations combining architecture (monolithic vs. hierarchical) and training method (robust vs. private). The goal is to identify structural advantages that enhance accuracy, stability, and interpretability while maintaining privacy and robustness guarantees.
# Background
Scaling laws in machine learning demonstrate that models generally achieve higher performance when provided with more data, larger model size, or greater computational resources. However, these rules do not always hold when models are trained under privacy-preserving constraints, such as differential privacy, where intentionally added noise can reduce model accuracy. Moreover, scaling laws do not inherently guarantee improvements in robustness, meaning the model’s ability to withstand adversarial attacks or unexpected input perturbations.
In conventional classification tasks, models are typically trained as single monolithic networks that map input data directly to all possible output classes. While this approach is straightforward, it may not be optimal for smaller models or settings where privacy and robustness are critical. The current project explores alternative model structures designed to enhance performance, robustness, and privacy in classification tasks, particularly for small models where resource limitations and strict privacy requirements are present.
# Objectives
This project aims to compare conventional single large models with stepwise, hierarchical classification models to determine which structure performs better under constrained conditions. A second objective is to evaluate how privacy-preserving training methods, such as Differentially Private Stochastic Gradient Descent (DP-SGD), affect the accuracy and stability of models. Together, these objectives will provide insights into whether hierarchical structures offer advantages over monolithic models on privacy and robustness separately. 
# Methodology
The baseline model is a standard monolithic classifier trained with gradient descent, which maps input features directly to all output classes in a single step. In contrast, the new structured model implements a hierarchical approach composed of three smaller sub-models. Model 1 serves as a coarse classifier that divides the input data into two broad categories. Models 2 and 3 are fine classifiers, further categorizing sub-types within each group. The output of Model 1 is used as a weighting factor that determines the contribution of Models 2 and 3 to the final classification decision.
Both the baseline and the hierarchical model will be trained under two distinct settings. The first is robustness-focused training, which uses minimax optimization to reduce vulnerability to adversarial examples. The second is privacy-preserving training, which applies DP-SGD to protect sensitive training data. These two training conditions create four experimental configurations: baseline-robustness, baseline-privacy, hierarchical-robustness, and hierarchical-privacy. For each configuration, key parameters such as learning rate, regularization strength, and noise magnitude will be optimized to maximize test accuracy while respecting robustness and privacy requirements.
# Measurements
The experiments will use the CIFAR-10 and CIFAR-100 datasets, which are standard benchmarks for image classification tasks. Test accuracy, defined as the proportion of correctly classified examples in the test set, is the primary performance metric. To ensure fairness across comparisons, training time will be controlled and kept constant for all models.
# Success Criteria
 A model structure will be considered successful if it achieves an absolute improvement of at least 1–2% in test accuracy compared to the baseline classifier. In addition, the model must maintain robustness under adversarial conditions when trained with minimax optimization, and it must preserve differential privacy guarantees when trained with DP-SGD. Meeting these criteria will demonstrate that the new structure provides practical improvements over the baseline.
# Architecture
<img width="954" height="499" alt="image" src="https://github.com/user-attachments/assets/70be1cee-2805-44fd-8b6f-97765362d37b" />

The input to the project is the image datasets CIFAR-10 and CIFAR-100, which contain labeled images for classification. These datasets are fed into two model structures: the baseline monolithic classifier and the hierarchical stepwise model. The baseline model takes the input images and maps them directly to all output classes in a single pass, producing predicted labels as the output. In contrast, the hierarchical model first passes the inputs to Model 1, a coarse classifier that divides the data into two broad categories. The outputs of Model 1 are then used as weighting factors to guide Models 2 and 3, which perform fine-grained classification within each coarse category. The weighted outputs from Models 2 and 3 are combined to produce the final prediction for each input image. 
